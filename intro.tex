\section{Introduction}

Cache, as an important component in software or hardware systems, aims to store temporary data for accelerating further requests.
Being widely applied in varied computer systems, cache typically provides lower latency and higher throughput, benefitting the systems' overall performance.
For instance, processor cache accelerates memory accesses by storing recently visited memory unit's value in faster storage media;
web cache records received large files, which are typically multimedia files in web pages, in local storage to reduce network traffic and response time.

Regardless of the cache type, maintaining the cache is always an essential task for ensuring its correctness, efficiency, and security.
Not well maintained, outdated cache might provide wrong value to requester, while complicated cache maintenance can bring significant performance degradation to computer systems~\cite{katz:iaccp}.
Moreover, unprotected cache can be leveraged to launch powerful side-channel attacks, severely threatening the system's security and reliability~\cite{fangfei:sidechannel}.
To make full use of cache while avoiding performance and security implications, researchers have proposed numerous cache maintenance techniques in the last decades.

Considering cache maintenance algorithms' complexity, variaty, and quantity, we focus on algorithms to maintain cache coherency in this notes.
Specifically, we elaborate on snoopy (or snooping) techniques~\cite{tang:csdittcms,goodman:ucmtrpt,katz:iaccp,em:dragon,thacker:firefly}, the most commonly used for maintaining processor cache coherency, as an example to illustrate how cache maintenance algorithms are designed.